{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41e1874",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"../All-sample-files/CC_BY.png\"><br />\n",
    "\n",
    "Created by [Nathan Kelber](http://nkelber.com) for [JSTOR Labs](https://labs.jstor.org/) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629c9a8",
   "metadata": {},
   "source": [
    "# Text Analysis Glossary\n",
    "\n",
    "A set of common text analysis terms with their definitions. This notebook does not contain executable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9d746",
   "metadata": {},
   "source": [
    "## Application Programming Interface (API)\n",
    "A protocol that defines communication between a client and server, often used to request data. APIs can help retrieve data from remote repositories, anything from weather to social media data.\n",
    "\n",
    "## Argument (in Python)\n",
    "An input that is passed into a function. For example,\n",
    "\n",
    "`print('Hello World')`\n",
    "\n",
    "passes the argument `'Hello World'` (a string variable) into a `print()` function.\n",
    "\n",
    "## Artificial Intelligence\n",
    "The science of making intelligent machines, especially machines that react to input data in a way similar to a human being. Historically, artificial intelligence has tended to rely on simple if-then statements (e.g. if the user mentions their mother, ask how she is doing), but recent advancements in artificial intelligence have focused on machine learning and generative content.\n",
    "\n",
    "## Assignment Statement (in Python)\n",
    "\n",
    "A statement that creates and/or changes a variable. For example,\n",
    "\n",
    "`new_variable = 7`\n",
    "\n",
    "Note that assignment statements use a single `=` sign. They should not be confused with the equality comparison operator `==`, which compares whether two values are equal and returns a boolean value, either **True** or **False**.\n",
    "\n",
    "## Bag of Words (Model)\n",
    "A model of texts that counts individual words without regard to grammatical location or phrases. Just as the letters of a Scrabble game are tossed into a bag without order, a \"bag of words\" model gathers all the words of a text into a \"bag\" with no regard to where a particular word occurs within the document. In this model, the reader knows every word and its frequency within the text but does not have the context of the word's use.\n",
    "\n",
    "## Bibliographic Metadata\n",
    "Also known as \"descriptive metadata,\" informational metadata that describes a published item such as a book or journal article.  Bibliographic metadata contains data elements to help users identify and retrieve the published items.   It often has a formalized bibliographic format.\n",
    "\n",
    "## Bigram\n",
    "An n-gram with a length of two. For example, \"chicken stock\" is a word bigram.\n",
    "\n",
    "## Bayesian Classification\n",
    "A classification method based on [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) that describes the probability of an event based on available prior knowledge. For example, given a dataset of the historical weather conditions (temperature, humidity, windspeed) from December 25th for every year over the last century, will it snow on December 25th, 2027?\n",
    "\n",
    "## Boolean Operator\n",
    "The operators:\n",
    "* and\n",
    "* or\n",
    "* not\n",
    "which are used in flow control statements to connect or separate expressions that evaluate to Boolean values.\n",
    "\n",
    "Assuming two expressions are connected by **and**, the combination will evaluate to **True** only if both individual expressions are **True**. \n",
    "\n",
    "|Expression|Evaluation|\n",
    "|---|---|\n",
    "|True and True|True|\n",
    "|True and False|False|\n",
    "|False and True|False|\n",
    "|False and False|False|\n",
    "\n",
    "Assuming two expressions are connected by **or**, the combination will evaluate to **False** only if both individual expressions are **False**\n",
    "\n",
    "|Expression|Evaluation|\n",
    "|---|---|\n",
    "|True or True|True|\n",
    "|True or False|True|\n",
    "|False or True|True|\n",
    "|False or False|False|\n",
    "\n",
    "## Boolean Value (in Python)\n",
    "A value of **True** or **False** (first letter must be capitalized) that is assigned to a variable, usually for the purpose of guiding a flow control statement. \n",
    "\n",
    "## Cell (in a Jupyter Notebook)\n",
    "See Code Cell (in a Jupyter Notebook) and Markdown Cell (in a Jupyter Notebook). \n",
    "\n",
    "## Clean Data\n",
    "Data that has been standardized and corrected for accurate results. This phrase can also be used as a verb such as \"to clean data\" or \"cleaning data.\" (Data cleaning is sometimes called \"munging.\") In practice, data cleaning makes up the bulk of text analysis work. \n",
    "\n",
    "## Clustering\n",
    "The statistical process of grouping together similar items. For example, topic analysis may cluster together sets of words that commonly co-occur, genre analysis may attempt to cluster similar genres, or authorship attribution may attempt to cluster novels by the same author. The clusters can be:\n",
    "\n",
    "* Hard Clusters (mutually exclusive groups)\n",
    "* Soft/Fuzzy Clusters (items may be in multiple groups)\n",
    "* Hierarchal Clusters (part of hierarchy)\n",
    "\n",
    "![visualization of cluster types](../All-sample-files/clustering_types.png)\n",
    "\n",
    "## Code Block (in Python)\n",
    "A snippet of code that begins with an indentation. A code block can be a single line or many lines long. Blocks can contain other blocks forming a hierarchal structure. In such a case, the second block is indented an additional degree. Any given block ends when the number of indentations in the current line is less than the number that started the block. \n",
    "\n",
    "![Visualization of code block indentations](../All-sample-files/code_block_indentation.png)\n",
    "\n",
    "## Code Cell (in a Jupyter Notebook)\n",
    "A cell in a Jupyter notebook that is executable. They can be distinguished by the presence of a set of brackets and a colon to the left of the cell. [ ]: \n",
    "\n",
    "See also, Markdown Cell (in a Jupyter Notebook). \n",
    "\n",
    "## Comparison Operator (in Python)\n",
    "\n",
    "A way to compare two values in Python to see if they are equal, greater than, or less than. \n",
    "\n",
    "|Operator|Meaning|\n",
    "|---|---|\n",
    "|==|Equal to|\n",
    "|!=|Not equal to|\n",
    "|<|Less than|\n",
    "|>|Greater than|\n",
    "|<=|Less than or equal to|\n",
    "|>=|Greater than or equal to|\n",
    "\n",
    "Note that the equality comparison operator is `==`, whereas a variable assignment statement is `=`. An expression using a comparison operator will evaluate to a boolean value, either **True** or **False**. Comparison operators are used within flow control statements to determine which code should be executed next.\n",
    "\n",
    "## Concordance\n",
    "A text analysis method for creating a list of all the occurences of a particular word or phrase. \n",
    "\n",
    "## Concatenation (of strings in Python)\n",
    "\n",
    "The joining of two or more strings such as with the addition operator.\n",
    "\n",
    "> 'Hello ' + 'World' + '!'\n",
    "\n",
    "evaluates to\n",
    "\n",
    "> 'Hello World!'\n",
    "> \n",
    "\n",
    "## Content Words\n",
    "As opposed to function words (e.g. articles, pronouns, conjuctions), content words (e.g. nouns, verbs, and adjectives) carry greater lexical meaning. Word frequency analysis typically attempts to filter out function words, in order to make content words more prominent. This filtering is accomplished with a stop words list.\n",
    "\n",
    "## Co-occurrence\n",
    "When two words occur close to one another, usually within the same sentence. \n",
    "\n",
    "## Corpus\n",
    "A large (and often structured) collection of texts used for analysis. For example, all of the plays written by Shakespeare. A simple example might be a set of plain text files in a folder on your computer. A more complicated example may use JSON, XML, or another form of markup, to allow for deeper analysis. The plural form is corpora.\n",
    "\n",
    "See also TEI XML. \n",
    "\n",
    "## Counter (in Python)\n",
    "A data type similar to a Python dictionary with a few key differences:\n",
    "* A counter object with a value of zero or less, always returns 0\n",
    "* When a key is called that doesn't exist in the counter, it returns 0 instead of an error like in a dictionary\n",
    "* A counter object has additional methods for counting including `.most_common(x)` that returns the x most common values.\n",
    "* Counter objects can be added, subtracted, as well as being modified through unions (&) and intersections (|)\n",
    "\n",
    "## CSV (file)\n",
    "A .csv file, or Comma-Separated Value file, is a simple format for storing structured data where each entry in the file is separated by a comma. Similarly, a TSV file uses tabs to separate individual data entries. \n",
    "\n",
    "## Dataframe (in Pandas)\n",
    "The primary data structure for analysis, manipulation, and presentation of data with the Pandas library.\n",
    "\n",
    "## Dataset\n",
    "A collection of information, usually computer files, used for statistical analysis. Most datasets are digital text (either numbers, words, or both), but they can also be other formats such as image, audio, and/or video content. Datasets are usually referred to as structured, semi-structured, or unstructured.\n",
    "* Structured data fits into a predetermined format and can usually be represented by a table, spreadsheet, or relational database. \n",
    "* Unstructured data is more freeform. For example, longform texts, audio, or video content are unstructured. \n",
    "* Semi-structured data uses tags or elements to mark out structures within an unstructured data set. Email files, for example, have both structured aspects (Sender, Subject, etc.), but the body of an email is usually unstructured.\n",
    "\n",
    "## Descriptive Metadata\n",
    "See bibliographic metadata.\n",
    "\n",
    "## Dictionary (in Python)\n",
    "A variable in Python that stores data in key/value pairs. This differs from a Python list which stores data in numberical order beginning with item 0.\n",
    "\n",
    "## Dictionary (gensim)\n",
    "A list created by gensim of all the words in a corpus. The command for creating a gensim dictionary:\n",
    ">gensim.corpora.Dictionary(documents)\n",
    "\n",
    "Each word in the corpus is assigned a unique gensim dictionary ID starting from 0. \n",
    "\n",
    "## Expression (in Python)\n",
    "\n",
    "A combination of values and operators in Python that evaluate to a single value. \n",
    "\n",
    "> 2 + 3\n",
    "\n",
    "is an expression using the addition operator (+) that evaluates to 5.\n",
    "\n",
    "## Floating-point number (float)\n",
    "A float is a data type that contains a decimal number that can assigned to a variable as a value. (Other kinds of data types in Python include strings and integers.) \n",
    "\n",
    "|  Data type             | Examples                                      |\n",
    "| -----------------------|:---------------------------------------------:|\n",
    "| Integers               | -5, -3, 0, 5, 201                             |\n",
    "| Floating-point numbers | -3.74, -3.14, 0.0, 503.4, 506                 | \n",
    "| Strings                | 'potatoes', 'Hello world!, 'no', '24 pizzas'  |\n",
    "\n",
    "## Flow Control Statement (in Python)\n",
    "A flow control statement guides the actions of a program, helping decide what code should be executed next depending on a series of tests such as:\n",
    "\n",
    "* `if` statements\n",
    "* `else` statements\n",
    "* `elif` statements\n",
    "* `while` loops\n",
    "* `for` loops\n",
    "\n",
    "## Function (in Python)\n",
    "A small snippet of code that can be referenced and run easily without having to be rewritten over again. There are three kinds of functions in Python:\n",
    "\n",
    "* Native functions built into Python\n",
    "* Functions others have written that can be imported\n",
    "* Functions a programmer defines themself\n",
    "\n",
    "Functions often take an input, in the form of an argument, and return an output. \n",
    "\n",
    "## Function Words\n",
    "The words in a sentence that have little lexical meaning and express grammatical relationships. Function words include articles, pronouns, and conjunctions. When using a word frequency approach, function words are often filtered out in favor of content words using a stopwords list. \n",
    "\n",
    "## Gensim\n",
    "A python library for implementing various natural language processing methods, such as TF-IDF, Word2Vec, and Topic Modeling.\n",
    "\n",
    "## git\n",
    "A method for saving versions of your computer code that enables many people to work on a single project. The code is stored in a repository (or \"repo\"). The git software is often used with a cloud service, such as [GitHub](http://github.com) and [GitLab](http://gitlab.com). \n",
    "\n",
    "## Global Scope (in Python)\n",
    "The entire scope of a program, not just the local scope of a particular function. A variable created in the global scope is a global variable that can be read from anywhere in the program. A global variable can be read within a local scope, but a local variable cannot be read at global scope.\n",
    "\n",
    "## Global Statement (in Python)\n",
    "A statement in the local scope of a function that declares a variable is a global variable. Without a global statement, the variable will be assumed to be a local variable during an assignment statement (even if there is a global variable with the same name). \n",
    "\n",
    "## Global Variable (in Python)\n",
    "A variable created in the global scope of a program. A global variable can be read within a local scope, but a local variable cannot be read at global scope.\n",
    "\n",
    "## Index Number (in Python)\n",
    "The items contained in a Python List are kept in a strict numerical order by index number, starting from 0. \n",
    "\n",
    "## Integer\n",
    "An integer is a data type that contains a whole number that can assigned to a variable as a value. (Other kinds of data types in Python include strings and floating point numbers.) \n",
    "\n",
    "|  Data type             | Examples                                      |\n",
    "| -----------------------|:---------------------------------------------:|\n",
    "| Integers               | -5, -3, 0, 5, 201                             |\n",
    "| Floating-point numbers | -3.74, -3.14, 0.0, 503.4, 506                 | \n",
    "| Strings                | 'potatoes', 'Hello world!, 'no', '24 pizzas'  |\n",
    "\n",
    "## JavaScript (Programming Language)\n",
    "An object-oriented computer programming language often used to create interactive effects within webbrowsers.  Learn more at [w3schools](https://www.w3schools.com/js/default.asp).\n",
    "\n",
    "## JSON (JavaScript Object Notation)\n",
    "An open-standard file format for storing and exchanging data that is intended to be easy to read and write humans and machines. Like XML, JSON is often used by APIs to transmit data from a remote repository (say weather data or Twitter data) to a local machine. \n",
    "\n",
    "## JSON Lines\n",
    "Also called newline-delimited JSON, JSON Lines (file extension .jsonl) is structured so it may be processed one record at a time. Each line is a valid value. The file extension for JSON Lines is \".jsonl\".\n",
    "\n",
    "## json (Python library)\n",
    "A library for interpreting and converting JSON into Python code.\n",
    "\n",
    "## JupyterHub\n",
    "A multi-user version of The Jupyter Notebook, ideal for teaching environments.\n",
    "\n",
    "## JupyterLab\n",
    "The newest software from Project Jupyter, intended to replace The Jupyter Notebook, for executing and editing Jupyter notebook files.\n",
    "\n",
    "## Jupyter Notebook, The (software)\n",
    "A single-user web application for executing and editing Jupyter notebook files. Will be replaced by JupyterLab.\n",
    "\n",
    "## Jupyter notebook (file)\n",
    "A file with extension .ipynb that contains computer code (e.g. Python or R) alongside other explanatory media (text, images, video).\n",
    "\n",
    "## Jupyter Server\n",
    "A server with the appropriate software environment (e.g. JupyterHub, JupyterLab) for running and editing Jupyter notebooks.\n",
    "\n",
    "## Key/Value Pair\n",
    "A key/value pair is a data organizational structure where a key is associated with a unique value or set of values. For example, the user could supply the key **Age** and receive a value **58 years**. \n",
    "\n",
    "In Python, Key/Value pairs are a key organizational structure for dictionaries and Counters.\n",
    "\n",
    "JSON also encodes key/value pairs, such as:\n",
    "\n",
    ">\"title\": \"The Souls of Black Folk\"\n",
    "\n",
    "where the key is \"title\" and the value is \"The Souls of Black Folk\". \n",
    "\n",
    "## Latent Dirichlet Allocation (LDA)\n",
    "An algorithm commonly used for topic modeling. Pronounced (lay-tent deer-ish-lay al-lo-cay-shun).\n",
    "\n",
    "## Lemmatization\n",
    "The process of grouping together the conjugated forms of a word into a base form. For example, \"jumping,\" \"jumped,\" and \"jumps\" could be combined into \"jump,\" the base form or *lemma*.\n",
    "\n",
    "## Library (in Python)\n",
    "A large collection of methods and functions for achieving certain tasks (e.g. image manipulation, web scraping). This saves time since the code can be added quickly and all at once around a specific group of tasks. The Natural Language Toolkit (NLTK) is a common library used in natural language processing.\n",
    "\n",
    "## List (in Python)\n",
    "A variable data type that stores items in numbered order beginning with item 0. The number for each item is called its index number. A list is different than a Python dictionary variable which stores data in key/value pairs. \n",
    "\n",
    "## List Comprehensions (in Python)\n",
    "A short way to create a Python list. For example, if you have:\n",
    "`list = [1,2,3,4,5,6,7,8,9,10]`\n",
    "A list comprehension could help generate a smaller list that only contains the even numbers.\n",
    "`evens_list = [x for x in list if x % 2 == 0]`\n",
    "Each item in the original list is checked to see if `x % 2 == 0` (if there is no remainder after being divided by 2). The resulting value of `evens_list` is `[2, 4, 6, 8, 10].`\n",
    "\n",
    "Alternatively, you could use a list comprehension to generate the evens_list from scratch. \n",
    "\n",
    "`evens_list = [x for x in range(11) if x % 2 == 0]`\n",
    "\n",
    "This would create a list, using the range from 0-11, where the number (called x here) is divisble by 2. Note that this list would include the number 0 since it is in the range from 0-11 and has a remainder of 0 when divided by 2.\n",
    "\n",
    "See also [documention on list comprehensions from python.org](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions).\n",
    "\n",
    "## Local Scope (in Python)\n",
    "The scope of a function where a local variable can be created and used without conflicting with higher-order, global variables. A global variable can be read within a local scope, but a local variable cannot be read at global scope.\n",
    "\n",
    "## Local Variable (in Python)\n",
    "A variable created in the local scope of a function. The variable name is erased after the function executes and is not accessible in the larger global scope of the program. A global variable can be read within a local scope, but a local variable cannot be read at global scope.\n",
    "\n",
    "## Machine Learning\n",
    "A subset of artificial intelligence that focuses on a machine algorithms that improve accuracy when exposed to additional data without being explicitly reprogrammed by a human.\n",
    "\n",
    "## Markdown Cell (in a Jupyter Notebook)\n",
    "\n",
    "A cell in a Jupyter notebook that contains explanatory information such as text, images, and links.\n",
    "\n",
    "See also Code Cell (in a Jupyter Notebook), which can contain executable code. \n",
    "\n",
    "## Metadata\n",
    "Data that describes data. In the humanities and library contexts, this often refers to bibliographic metadata that describes information such as author, publication date, medium, etc. It may also describe other kinds of data like files, for example \"date created\" or \"file size.\"\n",
    "\n",
    "## Method (in Python)\n",
    "Like a function, a method executes a set of pre-written code but on a particular object like a list. \n",
    "\n",
    "## Module (in Python)\n",
    "A set of functions that can be imported for use in a Python program. Modules can be gathered into even larger groups, such as a package or library.\n",
    "\n",
    "## Modulo (in Python)\n",
    "Notated as \"%\", an arithmetic operation that gives the remainder of a division. 34 % 6 = 4\n",
    "\n",
    "## N-gram\n",
    "A sequence of n items from a given sample of text or speech. Most often, this refers to a sequence of words, but it can also be used to analyze text at the level of syllables, letters, or phonemes. N-grams are often described by their length. For example, word n-grams might include:\n",
    "* stock (a 1-gram, or unigram)\n",
    "* chicken stock (a 2-gram, or bigram)\n",
    "* homemade chicken stock (a 3-gram, or trigram)\n",
    "A text analysis approach that looks only at unigrams at the word level will not be able to differentiate between the \"stock\" in \"stock market\" and \"chicken stock.\"\n",
    "\n",
    "One of the most popular examples of text analysis with n-grams is the [Google N-Gram Viewer](https://books.google.com/ngrams).\n",
    "\n",
    "## Named Entity Recognition (NER)\n",
    "A text analysis technique that seeks to identify and extract entities from a document. Entities could include things like:\n",
    "\n",
    "* Person\n",
    "* Organization\n",
    "* Date\n",
    "* Time\n",
    "* Location\n",
    "\n",
    "The Natural Language Toolkit, a suite of libraries in Python, can be used for Named Entity Recognition.\n",
    "\n",
    "## Natural Language Processing (NLP)\n",
    "The study of how computers can understand and manipulate natural human language whether in spoken or written forms. This includes areas such as:\n",
    "\n",
    "* Text Analysis\n",
    "* Natural Language Generation\n",
    "* Speech recognition\n",
    "* Transcription\n",
    "* Translation\n",
    "\n",
    "Natural Language Processing is a subfield that connects linguistics, computer science, information engineering, digital humanities, and data science.\n",
    "\n",
    "## Natural Language Toolkit (NLTK)\n",
    "A suite of libraries and programs for Natural Language Processing written in python. NLTK includes libraries for tokening, collocation, n-grams, Part of Speech (POS) Tagging, and Named Entity Recognition (NER).\n",
    "\n",
    "See the [project documentation](https://www.nltk.org/) and book [Natural Language Processing with Python](http://www.nltk.org/book/).\n",
    "\n",
    "## Neural Network (in Artificial Intelligence)\n",
    "In artificial intelligence (as opposed to biology), a neural network refers to a simplified model of brain neurons that enables machines to complete tasks through methods such as machine learning. Neural networks are commonly used on problems that involve data classification (Who is in this image?) and prediction (What price should this house sell for?). \n",
    "\n",
    "## Non-consumptive Research\n",
    "Non-consumptive research allows analysts to do text analysis without displaying or reading substantial portions of copyrighted materials. In practice, this usually means giving analysts a bag of words that describes the frequency of every word in a text but not the order in which they occur. \n",
    "\n",
    "## Operator (in Python)\n",
    "\n",
    "Changes a value through operations such as addition, multiplication, and concatenation.\n",
    "\n",
    "|Operator| Operation| Example | Evaluation |\n",
    "|---|----|---|---|\n",
    "|\\*\\*| Exponent/Power| 3 ** 3 | 27 |\n",
    "|%| Modulus/Remainder| 34 % 6 | 4 |\n",
    "|/| Division | 30 / 6 | 5|\n",
    "|\\*| Multiplication | 7 * 8 | 56 |\n",
    "|-| Subtraction | 18 - 4| 14|\n",
    "|+| Addition | 4 + 3 | 7 |\n",
    "\n",
    "## Optical Character Recognition (OCR)\n",
    "The process of turning printed text into machine-readable digital text. Physical materials are scanned into digital images then specialized software attempts to turn the image into text. Two popular examples of OCR software are [Tesseract (Open Source)](https://github.com/tesseract-ocr/tesseract) and [ABBYY Finereader (Proprietary)](https://www.abbyy.com/en-us/finereader/).\n",
    "\n",
    "## Package (in Python)\n",
    "A group of modules that contain functions that can be imported and used within a Python program. Packages can be gathered into a larger group called a library.\n",
    "\n",
    "## Pandas (in Python)\n",
    "A library for visualizing, analyzing, and manipulating data in Python. Learn more about [Pandas at pydata.org](https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html).\n",
    "\n",
    "## Parameter (in Python)\n",
    "A variable in a function definition statement. The actual value or variable passed during execution is called an argument.\n",
    "\n",
    "## Part of Speech (POS) Tagging\n",
    "The act of marking the grammatical part of speech (such as nouns, verbs, and adjectives) for each word in a document. The linguistic models for POS tagging can be very complex, often using over 100 separate parts of speech. \n",
    "\n",
    "POS Tagging can be accomplished using the Natural Language Toolkit in Python.\n",
    "\n",
    "## Plain text\n",
    "A file that only contains text and can be easily read in a text editor (as opposed to a binary or executable file)\n",
    "\n",
    "## Project Jupyter\n",
    "A non-profit that develops open-source software, open standards, and services across many programming languages. They are most well-known for software such as The Jupyter Notebook, JupyterLab, and JupyterHub. All three of these programs are used to create, edit, and share programming notebooks, known as Jupyter notebooks.\n",
    "\n",
    "## Python (Programming Language)\n",
    "A highly-flexible, easy-to-learn programming language that is widely-used in the digital humanities and data science.\n",
    "\n",
    "## R (Programming Language)\n",
    "A programming language that is widely-used for statistical analysis and data mining, commonly in the areas of digital humanities and data science.\n",
    "\n",
    "## Repository (for git, GitHub, GitLab, etc)\n",
    "Also known as a \"repo\". A repository is a place to store all the versions of the code for a computer programming project.\n",
    "\n",
    "See also git.\n",
    "\n",
    "## Sentiment Analysis\n",
    "A text analysis method that attempts to discover the emotions expressed in a sample of writing. Depending on the complexity of the method, it may discover simple distinctions (positive vs. negative) or more nuanced concepts (gratitude, anger, sadness, frustation, etc.).\n",
    "\n",
    "## Slice (in Python)\n",
    "A subset of items created from a list using index numbers.\n",
    "\n",
    "> example_list[2:4]\n",
    "\n",
    "The slice above creates a new list from `example_list` that contains the items at index 2 and 3 (but not 4).\n",
    "\n",
    "## Stemming\n",
    "Stemming is a method in text processing that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form. For example, \"chocolates\", after stemming, will be turned into \"chocolate\". Many natural language processing packages provide stemmers to do automated stemming. For example, NLTK has a stemmer -- the Porter Stemmer -- which stems \"immigrant\", \"immigrants\" and \"immigrantion\" into \"immigr\". \n",
    "\n",
    "## Stop Words (List)\n",
    "A stop words list is a set of words or phrases that are ignored in word frequency analysis. It is common for a researcher who is interested in prominent nouns and verbs to remove function words (e.g. the, and, I, to, of, a). A stop word list may also include other common words, such as character ids which are usually the most common words in a play text.\n",
    "\n",
    "## String (in Python)\n",
    "A string is a data type that contains a set of characters that can assigned to a variable as a value. (Other kinds of data types in Python include integers and floating point numbers.) \n",
    "\n",
    "|  Data type             | Examples                                      |\n",
    "| -----------------------|:---------------------------------------------:|\n",
    "| Integers               | -5, -3, 0, 5, 201                             |\n",
    "| Floating-point numbers | -3.74, -3.14, 0.0, 503.4, 506                 | \n",
    "| Strings                | 'potatoes', 'Hello world!, 'no', '24 pizzas'  |  \n",
    "\n",
    "## Tag Cloud (or Word Cloud)\n",
    "A tag cloud is a visualization of the relative word frequencies in a corpus. The relative size of each word in a tag cloud depends on its frequency within a text. Larger words occur more frequently.\n",
    "\n",
    "![Word Cloud of the content of journal African American Review](../All-sample-files/wordcloud.jpeg)\n",
    "\n",
    "**A Tag Cloud of the journal *African American Review* (and its precursors *Black American Literature Forum* and *Negro American Literature Forum*).** \n",
    "\n",
    "## TEI XML\n",
    "A form of XML Markup, or tagging, created by the [Text Encoding Initiative](https://tei-c.org/) to describe digital documents. This markup can help computers recognize particular aspects of the text. Text analysis often requires explicit marking, even for textual aspects that a human reader can easily pick out:\n",
    "* Title\n",
    "* Author Name\n",
    "* Name of the speaker in a play\n",
    "* A paragraph\n",
    "* The speaker in a play\n",
    "* Stage directions\n",
    "* A stanza\n",
    "\n",
    "See also Parts of Speech Tagging, Lemmatization, Tokenization.\n",
    "\n",
    "## Term Frequency-Inverse Document Frequency (TFIDF)\n",
    "A statistical method that intends to reflect how important a particular word is within a corpus. A simple measurement of \"term frequency\" is divided by inverse document frequency, limiting the weight of common words like \"the\", \"of\", and \"to\".\n",
    "\n",
    "## Token\n",
    "A chunk or string of text, most often a single word. The process of separating tokens in a document is called \"tokenization.\"\n",
    "\n",
    "## Topic Modeling (or Topic Analysis)\n",
    "\n",
    "A machine learning text analysis method that attempts to discover a group of words that cluster together in a set of documents. One of the most common algorithms for topic modeling is Latent Dirichlet Allocation (LDA). \n",
    "\n",
    "## Trigram\n",
    "An n-gram with a length of three. For example, \"homemade chicken stock\" is a word trigram.\n",
    "\n",
    "## TSV (file)\n",
    "A .tsv file, or Tab-Separated Value file, is a simple format for storing structured data where each entry in the file is separated by a tab. Similarly, a CSV file uses commas to separate individual data entries.\n",
    "\n",
    "## Tuple (in Python)\n",
    "A data type similar to a Python list, except that tuples are:\n",
    "\n",
    "1. Notated with parentheses\n",
    ">list = [1, 'monkey', 33.3234]\n",
    ">tuple = (1, 'monkey', 33.3234)\n",
    "\n",
    "2. Immutable. Like a string, the elements of a tuple cannot be changed. \n",
    "\n",
    "## Unigram\n",
    "An n-gram with a length of one. For example, \"chicken\" is a unigram.\n",
    "\n",
    "## Variable (in Python)\n",
    "A named object that stores a value in Python, such as an integer, float, or string. \n",
    "\n",
    "Variables are created with an assignment statement.\n",
    "\n",
    "## Voyant\n",
    "A flexible, web-based platform for text analysis that can also be run locally. [Voyant](https://voyant-tools.org/) has many kinds of visualizations, supports saving, and creates embeddable html objects. To learn more, see [the documentation](https://voyant-tools.org/docs/#!/guide/start). \n",
    "\n",
    "## Word2vec\n",
    "An algorithm that uses a neural network to create word embeddings.\n",
    "\n",
    "## Word Cloud\n",
    "See Tag Cloud.\n",
    "\n",
    "## Word Co-Occurrence Matrix\n",
    "A matrix that describes how often words co-occur. Co-occurrence usually means the words occur within the same sentence, but it could also mean within a set distance (such as within 3 words.)\n",
    "\n",
    "## Word Embedding\n",
    "A collective name for Natural Language Processing techniques that map words to vectors of real numbers using neural networks and dimensionality reduction on a word co-occurence matrix. Word2vec is a common model for producing word embeddings. \n",
    "\n",
    "## Word Frequency\n",
    "A text analysis method that counts the number of occurences of individual words within a particular text. Word frequency uses a bag of words model where the order of words is not significant. Just as the letters of a Scrabble game are tossed into a bag without order, word frequency merely records the number of occurences with no regard to where a particular word occurs within a document. \n",
    "\n",
    "An alternative to this approach is using n-grams which can capture phrases in addition to individual words.\n",
    "\n",
    "## XML\n",
    "Short for (eXtensible markup language), XML uses tags to identify parts of a document for a machine to understand. Like HTML, these tags have an opening tag (e.g. <l>) and a closing tag marked by a forward slash (e.g. </l>). Unlike HTML, these tags can be freely created according to whatever standard the creator needs. One prominent example is the [Text Encoding Initiative](https://tei-c.org/). The example below uses TEI-XML to describe Shakespeare's Sonnet 130 by labeling lines, quatrains, and the final couplet. This kind of markup enables computers to do complex analysis quickly such as comparing every couplet, quatrain, or line in Shakespeare's sonnets.\n",
    "```\n",
    "<text>\n",
    " <body>\n",
    "  <lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>My Mistres eyes are nothing like the Sunne,</l>\n",
    "    <l>Currall is farre more red, then her lips red</l>\n",
    "    <l>If snow be white, why then her brests are dun:</l>\n",
    "    <l>If haires be wiers, black wiers grown on her head:</l>\n",
    "   </lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>I have seene Roses damaskt, red and white,</l>\n",
    "    <l>But no such Roses see I in her cheekes,</l>\n",
    "    <l>And in some perfumes is there more delight,</l>\n",
    "    <l>Then in the breath that from my Mistres reekes.</l>\n",
    "   </lg>\n",
    "   <lg type=\"quatrain\">\n",
    "    <l>I love to heare her speake, yet well I know,</l>\n",
    "    <l>That Musicke hath a farre more pleasing sound:</l>\n",
    "    <l>I graunt I never saw a goddesse goe,</l>\n",
    "    <l>My Mistres when shee walkes treads on the ground.</l>\n",
    "   </lg>\n",
    "  </lg>\n",
    "  <lg type=\"couplet\">\n",
    "   <l>And yet by heaven I think my love as rare,</l>\n",
    "   <l>As any she beli'd with false compare.</l>\n",
    "  </lg>\n",
    " </body>\n",
    "</text>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cfeb9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
