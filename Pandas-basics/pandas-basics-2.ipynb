{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9988915",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "This notebook is adapted by Zhuo Chen from the notebooks created by [Nathan Kelber](https://github.com/ithaka/tdm-notebooks/blob/e6275296c010280909e90e3ea47922d52d99c5a7/pandas-2.ipynb), [William Mattingly](https://github.com/wjbmattingly/tap-2022-pandas) and [Melanie Walsh](https://github.com/melaniewalsh/Data-Analysis-with-Pandas) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email zhuo.chen@ithaka.org or nathan.kelber@ithaka.org.<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256a210",
   "metadata": {},
   "source": [
    "# Pandas Basics 2\n",
    "\n",
    "**Description:** This notebook describes how to:\n",
    "\n",
    "* Filter data in a dataframe\n",
    "* Work with missing values in a dataframe\n",
    "* Index a dataframe\n",
    "* Sort a dataframe\n",
    "\n",
    "This is the second notebook in a series on learning to use Pandas. \n",
    "\n",
    "**Use Case:** For Learners (Detailed explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Beginner\n",
    "\n",
    "**Knowledge Required:** \n",
    "* [Pandas 1](./pandas-basics-1.ipynb)\n",
    "* Python Basics ([Start Python Basics I](../Python-basics/python-basics-1.ipynb))\n",
    "\n",
    "**Knowledge Recommended:** \n",
    "* [Python Intermediate 2](../Python-intermediate/python-intermediate-2.ipynb)\n",
    "* [Python Intermediate 4](../Python-intermediate/python-intermediate-4.ipynb)\n",
    "\n",
    "**Completion Time:** 90 minutes\n",
    "\n",
    "**Data Format:** CSV (.csv)\n",
    "\n",
    "**Libraries Used:** Pandas\n",
    "\n",
    "**Research Pipeline:** None\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b27f7-8e8f-4962-a44a-da372ccc729a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas library, `as pd` allows us to shorten typing `pandas` to `pd` when we call pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5210835-e270-4c90-9923-cf665be55327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the display setting\n",
    "pd.set_option('display.min_rows', 20) # set the minimum number of rows to display to 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ab864",
   "metadata": {},
   "source": [
    "## Filter data in a dataframe\n",
    "A common pipeline in data processing in Pandas is that you create a dataframe from a file and then reduce the dataframe only to the rows and columns that you are interested in. \n",
    "\n",
    "We have learned how to use `.loc` and `.iloc` to select part of a dataframe in [Pandas Basics 1](./pandas-basics-1.ipynb). We will learn more ways to do data selection in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ce69b-806c-4b9b-b56d-6de205a3eedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download the sample file\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if a data folder exists. If not, create it.\n",
    "data_folder = Path('./data/')\n",
    "data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "url = 'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/Pandas1_failed_banks_since_2000.csv'\n",
    "file = './data/failed_banks.csv'\n",
    "urllib.request.urlretrieve(url, file)\n",
    "print('Sample file ready.')\n",
    "\n",
    "# Read in the data\n",
    "banks_df = pd.read_csv(file)\n",
    "banks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea8d2b3-6700-485f-81d2-71c46c79fda4",
   "metadata": {},
   "source": [
    "### The drop() method\n",
    "After creating a dataframe from a file, oftentimes we will drop certain rows or columns because we will not use them in the analysis anyways. In this case, we will use the `.drop()` method to remove those rows or columns.\n",
    "\n",
    "We can specify which column(s) to drop by using the 'columns' parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a108d-f683-431c-acf1-a92317c21d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop a column by setting the columns parameter\n",
    "banks_df.drop(columns='Fund')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ced11-7be9-417b-8fff-d32fc1f4c8ae",
   "metadata": {},
   "source": [
    "We can also drop multiple columns at one time. In this case, we just put the names for the columns we want to drop in a list and set the value of the `columns` parameter to the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d63395-7a96-4c00-8316-f884b7681d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop multiple columns by setting the columns parameter\n",
    "banks_df.drop(columns=['Fund', 'Cert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7bd04-9e54-472e-9528-dd558f33e3a7",
   "metadata": {},
   "source": [
    "Another way to drop a column is to give the label of the column you want to drop and then set the axis parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41027a8-06b1-4102-8229-a0543a16d34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop a column by setting the axis parameter\n",
    "banks_df.drop('Fund', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e0a06-6580-4829-8dd9-1d87038b4a2c",
   "metadata": {},
   "source": [
    "It might not be intuitive to you that axis 1 refers to the columns. Luckily, Pandas also allows us to set the axis parameter to `columns` when dropping columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42a02b-fe1e-499e-a2e0-754fa65dac89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop a column\n",
    "banks_df.drop('Fund', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7003ad-f7ce-4b1f-ba02-592c83644910",
   "metadata": {},
   "source": [
    "You can also drop multiple columns by setting the axis parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869bb7c3-9cb3-42e6-8699-89f0282b78bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop multiple columns by setting the axis parameter\n",
    "banks_df.drop(['Fund', 'Cert'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf5aa4-e1e3-4adc-84e9-304ade77faf9",
   "metadata": {},
   "source": [
    "To drop a row, you just pass the index number of the row to the `.drop()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd730fd-ac72-4dde-9323-70eebf78668a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop a row \n",
    "banks_df.drop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcdb4e-d8c8-4b89-80c8-c04d653294f2",
   "metadata": {},
   "source": [
    "If you assign the index number of the row to drop to the parameter `index`, you will get the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bc419-07d3-42b9-b9a0-069910d6b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop a row by setting the index parameter\n",
    "banks_df.drop(index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589511c7-dece-4e3b-acf5-97870bc65d26",
   "metadata": {},
   "source": [
    "To drop multiple rows, we just pass a list of index numbers to the `.drop()` method. Note that we don't need to specify the axis parameter. By default, Pandas knows that the list of index numbers are for the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06ea67-0fbb-47b2-80f8-adb8528d600e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop multiple rows \n",
    "banks_df.drop([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22cfdab-25f5-4fc4-bfc3-2cf69f06c4bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:33:31.066420Z",
     "iopub.status.busy": "2023-07-09T16:33:31.065586Z",
     "iopub.status.idle": "2023-07-09T16:33:31.090721Z",
     "shell.execute_reply": "2023-07-09T16:33:31.089836Z",
     "shell.execute_reply.started": "2023-07-09T16:33:31.066345Z"
    }
   },
   "source": [
    "Of course, you could specify the axis parameter to 0 or 'rows' to tell Pandas that you want to drop the rows with the given index numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d203a-e27f-4961-942f-4b7422f01307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows by setting the axis parameter\n",
    "banks_df.drop([0,1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab8924-b305-4709-bb34-61dc1bc26fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows by setting the axis parameter \n",
    "banks_df.drop([0,1], axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676a648-3630-4ab2-a534-afaf8ce19c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T14:50:28.659559Z",
     "iopub.status.busy": "2023-07-18T14:50:28.659172Z",
     "iopub.status.idle": "2023-07-18T14:50:28.684484Z",
     "shell.execute_reply": "2023-07-18T14:50:28.683788Z",
     "shell.execute_reply.started": "2023-07-18T14:50:28.659527Z"
    }
   },
   "source": [
    "Note that the `.drop()` method only returns a copy. This means that any change you make using the `.drop()` method will not affect the original dataframe. To make the change permanent, you can assign the result to the variable where you store the original dataframe to update it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f87b5-1f3b-4045-a059-01ee07f48d81",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; display:inline\">Coding Challenge! &lt; / &gt; </h3>\n",
    "\n",
    "In the exercises in this notebook, we'll work on a dataset built from Constellate.\n",
    "\n",
    "We'll use the `constellate` client to automatically retrieve the [metadata](https://constellate.org/docs/key-terms/#metadata) for a [dataset](https://constellate.org/docs/key-terms/#dataset). We can retrieve the [metadata](https://constellate.org/docs/key-terms/#metadata) in a [CSV file](https://constellate.org/docs/key-terms/#csv-file) using the `get_metadata` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf519db0-b16a-41a6-871a-d3b16346a547",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; display:inline\">Note! The following code cell assumes that you have downloaded the metadata csv file to the current working directory.&lt; / &gt; </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e975c6-5125-4b60-b03c-452bb36345c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_metadata = '' # copy and paste the path to your metadata csv file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fd4af-4520-45e9-850f-2cc83101d339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the type of the value stored in metadata\n",
    "type(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27e76-87fe-47cc-85f5-8ae02e64c491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print out the string stored in metadata\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce8894-e56d-4097-85b0-76e60665f2c4",
   "metadata": {},
   "source": [
    "The metadata is stored in a .csv file. In the following code cell, read in the data using Pandas. Give the dataframe a name. Then print out the dataframe to take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1f475-b041-44ce-8d55-27a2eb40b77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the csv file to a dataframe\n",
    "shake_df = pd.read_csv(metadata)\n",
    "shake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa10c3-bd5e-4729-a565-4b3b4cf2d7ba",
   "metadata": {},
   "source": [
    "Use a Pandas method to explore the dataframe. How many rows does it have? How many columns does it have? What is the data type of the data in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2496f60-c788-474c-a0ec-c1bdba795fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Pandas method to explore the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b799473-25a3-443e-86b3-62402b235197",
   "metadata": {},
   "source": [
    "When you explore the Shakespeare dataframe, what did you find about the column `doi`? What did you find about the column `placeOfPublication`? Drop the two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a371-b449-473a-9aab-e4a1ece9bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'doi' and 'placeOfPublication' columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230820cc-3518-421a-bdea-b9130efca977",
   "metadata": {},
   "source": [
    "### Work with missing values\n",
    "It is a common case that datasets have missing values. As you may have already noticed, blank cells in a csv file show up as NaN in a Pandas DataFrame. For example, in the dataset of failed banks, the `Acquiring Institution` column gives the name when a failed bank was acquired by another institution and has a value of NaN otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb123b-e25e-4e67-8b17-578d43bcf672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the missing values in banks_df\n",
    "banks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f2265-0fcf-49cc-973e-960d3b7da71f",
   "metadata": {},
   "source": [
    "To quickly get an idea of whether a dataframe has missing values, we can always use the `info()` method introduced in [Pandas Basics 1](./pandas-basics-1.ipynb) to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124139c-3b0c-4c6e-96dd-6a44e907a314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use info() to see whether there are missing values\n",
    "banks_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfc1cb-9118-4e96-aac1-15e91059b733",
   "metadata": {},
   "source": [
    "In Pandas, we can also use the `.isna()` method to check whether a pandas series or a dataframe has missing values. What this method does is it creates a boolean mask over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0192585-b153-4f54-a1d6-b28be782e74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use isna() to check whether a dataframe has missing values\n",
    "banks_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e4823",
   "metadata": {},
   "source": [
    "As we can see, the cells with a non-null value are masked with the boolean value of `False`. The cells with a null value are masked with the boolean value of `True`.\n",
    "\n",
    "Since `isna()` can check whether a pandas series has missing values, we can use `.isna()` to see whether a specific column in a dataframe has missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b3e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use isna() to check whether a column has missing values\n",
    "banks_df['Acquiring Institution'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb4b85-ece6-43f2-81c7-414935f321d9",
   "metadata": {},
   "source": [
    "#### Drop rows and columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597442",
   "metadata": {},
   "source": [
    "If you want to exclude the rows and columns with missing values from your data analysis, you can use the `.dropna()` method to do that.\n",
    "\n",
    "By default, the `.dropna()` method drops the rows with at least one missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b28b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .dropna() to remove all rows with at least one missing value\n",
    "banks_df.dropna() # no argument passed in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e282c",
   "metadata": {},
   "source": [
    "Based on what you have learned about the `.drop()` method, you now know that you can also set the axis parameter to 0 or 'rows' to drop the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96755288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .dropna() to remove all rows with at least one missing value\n",
    "banks_df.dropna(axis=0) # Set the axis to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bfe15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .dropna() to remove all rows with at least one missing value\n",
    "banks_df.dropna(axis='rows') # Set the axis to 'rows'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77961d",
   "metadata": {},
   "source": [
    "If you set the axis parameter to 1 or 'columns', you will drop the columns with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdff9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .dropna() to remove all columns with at least one missing value\n",
    "banks_df.dropna(axis=1) # set the axis to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f67b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .dropna() to remove all columns with at least one missing value\n",
    "banks_df.dropna(axis='columns') # set the axis to 'columns'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146502d",
   "metadata": {},
   "source": [
    "Sometimes we would want to drop a row only if that row has a missing value in a specific column. We can use the subset parameter to specify the column(s) to look for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2bb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the columns to look for missing values\n",
    "banks_df.dropna(subset=['Acquiring Institution', 'City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806aa7b-d2c5-41e8-be16-ab6b80e4cbc0",
   "metadata": {},
   "source": [
    "Note that the `.dropna()` method only returns a copy. This means that any change you make using the `.dropna()` method will not affect the original dataframe. To make the change permanent, you can assign the result to the variable where you store the original dataframe to update it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67377950-d0fc-499c-b71f-230f04d16af1",
   "metadata": {},
   "source": [
    "Oftentimes, you would want to maintain the rows and columns that have missing values. However, you would want to fill the cells with NaN values with some values which are of the same data type as the other cells in the same column. In this way, when you apply a certain function to a column in a dataframe, you will not run into type error. A common practice to deal with this kind of problem is to use the `.fillna()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b4fb6-4f96-4959-95b9-7fd5b52d68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing values\n",
    "banks_df['Acquiring Institution'].fillna('No Acquirer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81696-c697-4448-931e-87b2ce3f6613",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; display:inline\">Coding Challenge! &lt; / &gt; </h3>\n",
    "\n",
    "Let's grab the Shakespeare dataframe we have created and do some further filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd893af-87bb-457c-81dd-09878e066725",
   "metadata": {},
   "source": [
    "When you explore the Shakespeare dataframe, what did you find about the column `pagestart`? What did you find about the column `pageEnd`? Suppose you will need the page range information in your analysis. Therefore, you will want to drop any rows with missing values in these two columns. How do you do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943c994-9acb-4645-8782-df056ae35a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values in 'pageStart' or 'pageEnd'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2558483",
   "metadata": {},
   "source": [
    "#### Filter data using conditionals\n",
    "Conditional selection using `df.loc[]` is a very common method to filter a dataframe. \n",
    "\n",
    "You write a filtering condition to filter a target column. The condition then checks, for each cell in the target column, whether it fulfills the condition or not. The results will be returned as a Series of True/False values. The `.loc` indexer then uses this Series to select the rows that have True values. \n",
    "\n",
    "Suppose you are interested in the banks that failed since 2000 in the state of Georgia. From the original dataframe, you would like to get all the rows of the failed banks in Georgia. How do you do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370115e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a filtering condition\n",
    "banks_df['State'] == 'GA' # Create a boolean mask over the column 'State'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1f9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the filtering condition to a variable\n",
    "filt = (banks_df['State'] == 'GA') # Use parenthesis for better reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d33e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put the Series returned by the filtering condition within the hard brackets of banks_df.loc[]\n",
    "banks_df.loc[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09b9ac",
   "metadata": {},
   "source": [
    "Out of the rows that fulfill the filtering condition, we can further specify which columns to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f94a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify a single column to be returned\n",
    "banks_df.loc[filt, 'Bank Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbeb58",
   "metadata": {},
   "source": [
    "Of course, we can select muliple columns to be returned out of the filtered rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817b6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify multiple columns to be returned\n",
    "banks_df.loc[filt, ['Bank Name', 'Fund']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0392af",
   "metadata": {},
   "source": [
    "Now suppose you want to get all the failed banks whose name contains the word 'community'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d47db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all the banks with the word 'community' in their name\n",
    "filt = (banks_df['Bank Name'].str.contains('Community'))\n",
    "banks_df.loc[filt, ['Bank Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d6285",
   "metadata": {},
   "source": [
    "#### Conjunction of multiple filtering conditions: `&`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4de31f",
   "metadata": {},
   "source": [
    "Oftentimes, you would want to filter a dataframe based on more complex conditions. For example, suppose you would like to get the banks in GA that were closed between 2008 and 2010. How do you use `df.loc[ ]` to achieve it?\n",
    "\n",
    "The location of the failed banks is stored in the `State` column. The closing year of the banks is stored in the `Closing Date` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f32c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the first filtering condition restricting the state\n",
    "filt1 = (banks_df['State'] == 'GA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d706d4c",
   "metadata": {},
   "source": [
    "How to get the closing year of the banks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94dd51-7c9c-41b2-a69a-a8b28f81bb97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the data type of the 'Closing Date' column\n",
    "banks_df['Closing Date'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20340323",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new column storing the closing year of the banks\n",
    "banks_df['Closing Year'] = banks_df['Closing Date'].str[-2:].astype(int) + 2000\n",
    "banks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232d8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the second filtering condition restricting the closing year\n",
    "filt2 = (banks_df['Closing Year'] > 2007) & (banks_df['Closing Year'] < 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1523c",
   "metadata": {},
   "source": [
    "With the two filtering conditions, we are ready to extract the banks in GA that failed between 2008 and 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33211dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use filt1 and filt2 to get the target rows\n",
    "banks_df.loc[filt1 & filt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb5f3a",
   "metadata": {},
   "source": [
    "Note that when we extract rows that fulfill multiple conditions, we use `&` in Pandas, not `and`. If you replace `&` with `and`, you will get an error. This is different than what we have learned about boolean operators in [Python basics 2](../Python-basics/python-basics-2.ipynb). In Python, we use `and`, `or` and `not`. In Pandas, we use `&`, `|` and `~` intead. \n",
    "\n",
    "|Pandas Operator|Boolean|Requires|\n",
    "|---|---|---|\n",
    "|&|and|All required to `True`|\n",
    "|\\||or|If any are `True`|\n",
    "|~|not|The opposite|\n",
    "\n",
    "Although we use different symbols for these boolean operators, the truth table for them stays the same. For a quick review of the truth table, see [Python basics 2](../Python-basics/python-basics-2.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408cf91",
   "metadata": {},
   "source": [
    "#### Disjunction of multiple filtering conditions: `|`\n",
    "Suppose you would like to take a look at all the failed banks in the state of Georgia or the state of New York. How do you use `df.loc[]` to get the target rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7883a42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the two filtering conditions restricting the state to GA and NY\n",
    "filt1 = (banks_df['State'] == 'GA')\n",
    "filt2 = (banks_df['State'] == 'NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db210a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use filt1 and filt2 to get the target rows\n",
    "banks_df.loc[filt1|filt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6c8a5",
   "metadata": {},
   "source": [
    "If you would like to get the data of the failed banks in the following six states --- Georgia, New York, New Jersey, Florida, California and West Virginia, you will not want to write six filtering conditions and use the vertical bar `|` to connect all of them. That would be too repetitive. In this case, we can use the `.isin()` method to create a filtering condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa9d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of the states\n",
    "states = ['GA', 'NY', 'NJ', 'FL', 'CA', 'WV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c9bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a filtering condition\n",
    "filt = (banks_df['State'].isin(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47e53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use filt to find all failed banks in the six states\n",
    "banks_df.loc[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84832e5e",
   "metadata": {},
   "source": [
    "#### Negation of a certain condition:`~`\n",
    "Now, suppose you would like to get all the failed banks that were **not** closed in 2008. How do you do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6094339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the filtering condition restricting the closing year to non-2008\n",
    "filt = (~(banks_df['Closing Year'] == 2008))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc4ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the filtering condition to get the target rows with specified columns\n",
    "banks_df.loc[filt, ['Bank Name', 'City']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a950550",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; display:inline\">Coding Challenge! &lt; / &gt; </h3>\n",
    "\n",
    "Let's do some filtering!\n",
    "\n",
    "From the Shakespeare dataframe, get the title and the creator of the documents published between 2000 **and** 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b08fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the title and creator of docs published between 2000 and 2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf237e0",
   "metadata": {},
   "source": [
    "From the Shakespeare dataframe, get the creator of the documents shorter than 10 pages **or** longer than 50 pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb49b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the creator of the docs shorter than 10 pages or longer than 50 pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be034e9d",
   "metadata": {},
   "source": [
    "From the Shakespeare dataframe, get the title of the documents whose publisher is **not** Folger Shakespeare Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the title of the docs whose publisher is NOT Folger Shakespeare Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067d4ec-0b8f-4718-950a-93fc50cd8b3a",
   "metadata": {},
   "source": [
    "## Index a dataframe \n",
    "\n",
    "In this section, we'll continue to work with the dataframe we created in [Pandas 1](./pandas-basics-1.ipynb) storing data on the most recent 10 World Cup games.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bf174-c897-46e0-b13f-28b3551a14e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with world cup data\n",
    "wcup = pd.DataFrame({\"Year\": [2022, \n",
    "                              2018, \n",
    "                              2014, \n",
    "                              2010, \n",
    "                              2006, \n",
    "                              2002, \n",
    "                              1998, \n",
    "                              1994, \n",
    "                              1990,\n",
    "                              1986], \n",
    "                     \"Champion\": [\"Argentina\", \n",
    "                                  \"France\", \n",
    "                                  \"Germany\", \n",
    "                                  \"Spain\", \n",
    "                                  \"Italy\", \n",
    "                                  \"Brazil\", \n",
    "                                  \"France\", \n",
    "                                  \"Brazil\", \n",
    "                                  \"Germany\", \n",
    "                                  \"Argentina\"], \n",
    "                     \"Host\": [\"Qatar\", \n",
    "                              \"Russia\", \n",
    "                              \"Brazil\", \n",
    "                              \"South Africa\", \n",
    "                              \"Germany\", \n",
    "                              \"Korea/Japan\", \n",
    "                              \"France\", \n",
    "                              \"USA\", \n",
    "                              \"Italy\", \n",
    "                              \"Mexico\"],\n",
    "                     \"Score\": [\"7-5\", \n",
    "                               \"4-2\", \n",
    "                               \"1-0\", \n",
    "                               \"1-0\", \n",
    "                               \"6-4\", \n",
    "                               \"2-0\", \n",
    "                               \"3-0\", \n",
    "                               \"3-2\", \n",
    "                               \"1-0\", \n",
    "                               \"3-2\"]\n",
    "                    })\n",
    "wcup['Goals Scored'] = wcup['Score'].str[0]\n",
    "wcup['Goals Conceded'] = wcup['Score'].str[-1]\n",
    "wcup['Difference'] = wcup['Goals Scored'].astype(int) - wcup['Goals Conceded'].astype(int)\n",
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633f920-43f6-4bc0-b94f-a18b4ee8d010",
   "metadata": {},
   "source": [
    "### Set, reset and use indexes\n",
    "We have seen that by default, the rows in a dataframe are numbered by integer indexes starting from 0. The indexes look like a column to the far left without a name. \n",
    "\n",
    "We can set the index column to one of the columns in the dataframe. This is desirable because a range of integers is not descriptive but a column with a name is descriptive. When we want to locate specific data, descriptive labels are much more useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34ce36-c724-4a3c-aa27-57c49e3252b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the index column to 'Year'\n",
    "wcup.set_index('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86454113-286c-43f4-9e6a-710a21e2c864",
   "metadata": {},
   "source": [
    "Take a look at the original dataframe, is it changed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24b786-c5d8-4946-b17e-d89a412a48f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the original dataframe\n",
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d95e66-392e-4cc2-b219-aa14256d3138",
   "metadata": {},
   "source": [
    "The original dataframe is **NOT** changed after we use the `.set_index()` method to change the index column. The `.set_index()` method returns a copy, this is why the original dataframe is not affected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8396a9-6145-41fe-a451-726e6af19507",
   "metadata": {},
   "source": [
    "If you want to make the change permanent, you can assign the returned object to the variable where you store the original dataframe to update it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644e526-084d-4111-9e43-790cc3b1ab40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the index column and commit the change\n",
    "wcup = wcup.set_index('Year')\n",
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a105538-7bfc-463d-b4ab-bcc4f9783f88",
   "metadata": {},
   "source": [
    "You can change the index column back to the default integer index column using the `reset_index()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ad3fc-7bc5-4471-824c-f1d684bf030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indexes to the integer indexes\n",
    "wcup.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c47698-e8ad-41f0-aaa0-39fca7b3f604",
   "metadata": {},
   "source": [
    "## Sort a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b18be-8203-4028-9cac-1c9102e19b99",
   "metadata": {},
   "source": [
    "A common use of the index column is to sort a dataframe. Here, we have 'Year', a numerical column as our index column. When we sort the indexes, by default, the dataframe will be sorted by the index column in an ascending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7666b0-7816-4875-8085-b4fd4ea9238a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by the index column\n",
    "wcup.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e879699-84e5-4892-a1c9-78d64bfbd46a",
   "metadata": {},
   "source": [
    "You could set the parameter `ascending=False` to sort the indexes in a descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936266fa-3f91-418c-aa28-7d8a1e9b1878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the ascending order\n",
    "wcup.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff00ea-8794-4a13-b6b4-5d61157e9b14",
   "metadata": {},
   "source": [
    "### Sort by one column\n",
    "\n",
    "We can sort the entire dataframe by a column other than the index column. The `.sort_values()` method helps us do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4d7bc-f61f-486f-ad5c-3f37a869d8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by the column 'Goals Scored'\n",
    "wcup.sort_values(by=['Goals Scored'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768764b0-b81d-4652-97e2-81f6bcc96240",
   "metadata": {},
   "source": [
    "### Sort by multiple columns\n",
    "It is a convention to sort the soccer results first by difference (i.e. how many more goals the champion scored than the runner-up) and then by goals conceded (i.e. how many goals the champion lost). Pandas can easily do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef202e59-2449-4fad-af9a-b5de0dcf1ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by Difference column in descending order \n",
    "# then by Goals Conceded column in ascending order\n",
    "wcup.sort_values(by=['Difference', 'Goals Conceded'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff64e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset the index for later use\n",
    "wcup = wcup.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a0282-fc64-44d9-8078-28abb44e8af9",
   "metadata": {},
   "source": [
    "### Hierarchical indexing\n",
    "Sorting by multiple columns helps us group the data in a certain way. For example, in the world cup dataframe, if we would like to group the data first by the champions and then by the years, we can sort the dataframe by these two columns and set the two columns as the a multi-level index of the dataframe. The `Champion` column will be the level 0 index and the `Year` column will be the level 1 index. The hierarchical indexing allows us to work with higher dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac09428-6223-4c9a-9944-7e0f132bfc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First,sort the two columns we will use for multi-level indexing\n",
    "# Then, set the index to the composite of Champion and Year\n",
    "wcup = wcup.sort_values(by=['Champion', 'Year'], ascending=[1,0]).set_index(['Champion', 'Year'])\n",
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac3b84-527f-418e-9c0e-30ac5fe16403",
   "metadata": {},
   "source": [
    "If a dataframe has a multi-level index, to access a certain row, we will need to provide a multi-level index in order to access it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080c087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the data on the 1986 world cup game won by Argentina\n",
    "wcup.loc[('Argentina', 1986)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f3b7c-90f3-43f7-bbf8-803f9e3db10c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; display:inline\">Coding Challenge! &lt; / &gt; </h3>\n",
    "\n",
    "In this coding challenge, we'll use the Shakespeare dataframe. Use what you have learned about sorting and indexing a dataframe to answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efaa80-3361-477a-938f-dea963f135b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the Shakespeare df\n",
    "shake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc6e6-3bcb-424a-b2ba-70dea9c792f2",
   "metadata": {},
   "source": [
    "Which doc(s) are the longest in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02132723-933c-45df-a8e7-ce9ffad65be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the longest doc(s) in the df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6c241-1382-4d48-810c-b272181bb1a2",
   "metadata": {},
   "source": [
    "Among the docs published in 1983, how many were published by Folger Shakespeare Library? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c9566-a146-4d89-9a47-bfb5261eee2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Among the docs published in 1983, how many were published by Folger Shakespeare Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e3f5d-b297-4403-9f2d-67d732e13db2",
   "metadata": {},
   "source": [
    "___\n",
    "## Lesson Complete\n",
    "\n",
    "Congratulations! You have completed *Pandas Basics 2*.\n",
    "\n",
    "### Start Next Lesson: [Pandas 3 ->](./pandas-basics-3.ipynb)\n",
    "\n",
    "### Exercise Solutions\n",
    "Here are a few solutions for exercises in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5293113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a variable `dataset_id` to hold our dataset ID\n",
    "# The default dataset is Shakespeare Quarterly, 1950-present\n",
    "# retrieve the metadata\n",
    "metadata = ''\n",
    "\n",
    "# Create a dataframe\n",
    "shake_df = pd.read_csv(metadata)\n",
    "\n",
    "# Explore the dataframe\n",
    "shake_df.info()\n",
    "\n",
    "# Drop the columns of doi and the placeofPublication, make the change permanent\n",
    "shake_df = shake_df.drop(columns=['doi', 'placeOfPublication'])\n",
    "\n",
    "# Drop the rows with missing values in 'pageStart' or 'pageEnd'\n",
    "shake_df = shake_df.dropna(subset=['pageStart', 'pageEnd'])\n",
    "\n",
    "shake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the title and the creator of the documents published between 2000 and 2010\n",
    "filt = (shake_df['publicationYear']>1999) & (shake_df['publicationYear']<2011)\n",
    "shake_df.loc[filt, ['title', 'creator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the creator of the documents shorter than 10 pages or longer than 50 pages\n",
    "filt = (shake_df['pageCount']<10)|(shake_df['pageCount']>50)\n",
    "shake_df.loc[filt, 'creator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the title of the documents whose publisher is not Folger Shakespeare Library\n",
    "filt = (shake_df['publisher']=='Folger Shakespeare Library')\n",
    "shake_df.loc[~filt, 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70017580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the longest doc(s) in the dataset\n",
    "shake_df.loc[:, ['title', 'pageCount']].sort_values(by='pageCount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db2545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the number of docs published by Folger Shakespeare Library in 1983\n",
    "shake_df.set_index(['publicationYear', 'publisher']).sort_index().loc[(1983, 'Folger Shakespeare Library')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19e419-327e-43a7-9392-ac384efa7256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
